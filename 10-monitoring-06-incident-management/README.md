# Домашнее задание к занятию "10.06. Инцидент-менеджмент"

## Задание 

Составьте постмортем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

### Ответ:

Постмортем  


| Краткое описание инцидента  | 21 октября 2018 года кратковременный сбой вызвал цепочку событий, которые привели к ухудшению качества обслуживания на 24 часа 11 минут.
------------- | ------------- 
| Предшествующие события | В 22:52 UTC 21 октября 2018 года плановые работы по замене вышедшего из строя оптического оборудования 100G привели к потере связи между  сетевым концентратором на восточном побережье США и основным центром обработки данных на восточном побережье США. Связь между этими точками была восстановлена ​​за 43 секунды. 
| Причина инцидента | Серверы базы данных в центре обработки данных на восточном побережье США содержали короткий период записи, который не был реплицирован на объект на западном побережье США. Поскольку кластеры баз данных в обоих центрах обработки данных теперь содержали записи, которых не было в другом центре обработки данных, мы не смогли безопасно выполнить возврат основного сервера в центр обработки данных на восточном побережье США.
| Воздействие | Весь функционал github частично перестал функционировать. git push не проходит, репозитории не создаются, созданные pull request, Issue и записи комментариев к уже существующим Issue визуально отображаются а после перезагрузки — пропадают.
| Обнаружение | Внутренние системы мониторинга начали генерировать предупреждения, указывающие на многочисленные сбои в системах. В это время несколько инженеров отвечали и работали над сортировкой входящих уведомлений. К 23:02 UTC инженеры группы быстрого реагирования определили, что топологии многочисленных кластеров баз данных находятся в непредвиденном состоянии. 
| Реакция | Отвечающая команда решила вручную заблокировать внутренний инструмент развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений. Команда респондентов поместила сайт в желтый статус . Это действие автоматически переводит ситуацию в активный инцидент и отправляет предупреждение координатору инцидентов. В 23:11 по всемирному координированному времени присоединился координатор инцидента и через две минуты изменил статус решения на красный. 
| Восстановление | План состоял в том, чтобы восстановить из резервных копий, синхронизировать реплики на обоих сайтах, вернуться к стабильной топологии обслуживания, а затем возобновить обработку заданий в очереди.
| Таймлайн | - 2018 21 октября 22:52 UTC Серверы базы данных в центре обработки данных на восточном побережье США содержали короткий период записи, который не был реплицирован на объект на западном побережье США.<br>- 2018 21 октября 22:54 UTC Внутренние системы мониторинга начали генерировать предупреждения, указывающие на многочисленные сбои в наших системах.<br>- 2018 21 октября 23:07 UTC К этому моменту отвечающая команда решила вручную заблокировать наш внутренний инструмент развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений.<br>- 21 октября 23:09 UTC Команда респондентов поместила сайт в желтый статус.<br>- 21 октября 23:11 UTC Присоединился координатор инцидента и через две минуты изменил статус решения на красный.<br>- 2018 21 октября 23:13 UTC Были вызваны дополнительные инженеры из группы разработки баз данных GitHub.<br>- 2018 21 октября 23:19 UTC Из запроса состояния кластеров базы данных стало ясно, что нам нужно остановить выполнение заданий, записывающих метаданные о таких вещах, как push-уведомления.<br>- 22 октября 2018 г., 00:05 UTC Инженеры, участвующие в группе реагирования на инциденты, начали разработку плана по устранению несоответствий данных и внедрению наших процедур аварийного переключения для MySQL.<br>- 22 октября 2018 г., 00:41 UTC К этому времени был инициирован процесс резервного копирования для всех затронутых кластеров MySQL, и инженеры следили за его ходом.<br>- 22 октября 2018 г., 06:51 UTC Несколько кластеров завершили восстановление из резервных копий в нашем центре обработки данных на восточном побережье США и начали репликацию новых данных с западного побережья.<br>- 22 октября 2018 07:46 UTC GitHub опубликовал сообщение в блоге , чтобы предоставить больше информации.<br>- 22 октября 2018 г., 11:12 UTC Все первичные базы данных снова установлены на восточном побережье США.<br>- 22 октября 2018 г., 13:15 UTC К настоящему времени мы приближались к пиковой нагрузке трафика на GitHub.com. Группа реагирования на инциденты обсудила, как действовать дальше.<br>- 22 октября 2018 г., 16:24 UTC Как только реплики были синхронизированы, мы выполнили аварийное переключение на исходную топологию, решив немедленные проблемы с задержкой/доступностью.<br>- 22 октября 2018 г., 16:45 UTC На этом этапе восстановления нам пришлось сбалансировать возросшую нагрузку, представленную отставанием, потенциально перегружая наших партнеров по экосистеме уведомлениями, и как можно быстрее вернуть наши услуги на 100%. В очереди было более пяти миллионов событий ловушек и 80 тысяч сборок страниц.<br>- 22 октября 2018 23:03 UTC Все ожидающие сборки вебхуков и страниц были обработаны, и была подтверждена целостность и правильная работа всех систем. Статус сайта был обновлен до зеленого.
| Последующие действия| В ходе этого анализа был выявлен ряд технических инициатив. По мере того, как мы продолжаем проводить обширный внутренний анализ после инцидента, мы рассчитываем определить еще больше работы, которую необходимо выполнить.<br><br>1. Настройте конфигурацию Orchestrator, чтобы предотвратить продвижение основных баз данных через региональные границы. Действия Оркестратора вели себя так, как настроено, несмотря на то, что наш уровень приложений не смог поддержать это изменение топологии. Выборы лидеров в регионе, как правило, безопасны, но внезапная задержка между странами стала основным фактором, способствовавшим этому инциденту. Это было неожиданное поведение системы, учитывая, что ранее мы не видели внутреннего сетевого раздела такого масштаба.<br>2. Мы ускорили переход на новый механизм отчетов о состоянии, который предоставит нам более богатый форум для обсуждения активных инцидентов более четким и понятным языком. Хотя во время инцидента многие части GitHub были доступны, мы смогли установить только зеленый, желтый и красный статус. Мы понимаем, что это не дает вам точного представления о том, что работает, а что нет, и в будущем мы будем отображать различные компоненты платформы, чтобы вы знали статус каждой службы.<br>3. За несколько недель до этого инцидента мы начали общекорпоративную инженерную инициативу по поддержке обслуживания трафика GitHub из нескольких центров обработки данных в схеме «активный/активный/активный». Целью этого проекта является поддержка резервирования N+1 на уровне объекта. Цель этой работы — допустить полный отказ одного центра обработки данных без воздействия на пользователя. Это серьезное усилие, которое займет некоторое время, но мы считаем, что наличие нескольких сайтов с хорошей связью в одном регионе обеспечивает хороший набор компромиссов. Этот инцидент добавил актуальности инициативе.<br>4. Мы займем более активную позицию в проверке наших предположений. GitHub — быстрорастущая компания, и за последнее десятилетие она значительно усложнилась. По мере того, как мы продолжаем расти, становится все труднее фиксировать и передавать исторический контекст компромиссов и решений, принятых новым поколениям Хабберов.







---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
